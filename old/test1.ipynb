{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73cd98bc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-21T09:58:12.317363Z",
     "start_time": "2025-05-21T09:58:12.060813Z"
    },
    "execution": {
     "iopub.execute_input": "2025-05-21T09:19:02.857272Z",
     "iopub.status.busy": "2025-05-21T09:19:02.856882Z",
     "iopub.status.idle": "2025-05-21T09:19:07.635636Z",
     "shell.execute_reply": "2025-05-21T09:19:07.634619Z",
     "shell.execute_reply.started": "2025-05-21T09:19:02.857241Z"
    },
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a3f3f31-b57c-428f-b1a9-b21a2373d858",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-21T09:58:12.325299Z",
     "start_time": "2025-05-21T09:58:12.320266Z"
    },
    "execution": {
     "iopub.execute_input": "2025-05-21T09:19:21.500609Z",
     "iopub.status.busy": "2025-05-21T09:19:21.500126Z",
     "iopub.status.idle": "2025-05-21T09:19:21.507261Z",
     "shell.execute_reply": "2025-05-21T09:19:21.506302Z",
     "shell.execute_reply.started": "2025-05-21T09:19:21.500577Z"
    }
   },
   "outputs": [],
   "source": [
    "class DiscreteCarRacingWrapper(gym.ActionWrapper):\n",
    "    def __init__(self, env):\n",
    "        super().__init__(env)\n",
    "        # Define a set of discrete actions: [steer, gas, brake]\n",
    "        self.actions = [\n",
    "            np.array([0.0, 0.0, 0.0]),   # Do nothing\n",
    "            np.array([-1.0, 1.0, 0.0]),  # Turn left + gas\n",
    "            np.array([1.0, 1.0, 0.0]),   # Turn right + gas\n",
    "            np.array([0.0, 1.0, 0.0]),   # Straight + gas\n",
    "            np.array([0.0, 0.0, 0.8]),   # Brake\n",
    "        ]\n",
    "        self.action_space = gym.spaces.Discrete(len(self.actions))\n",
    "\n",
    "    def action(self, action_index):\n",
    "        return self.actions[action_index]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6c6b5a5-4900-4ec7-8c47-972267f876f7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-21T09:58:12.619291Z",
     "start_time": "2025-05-21T09:58:12.462348Z"
    },
    "execution": {
     "iopub.execute_input": "2025-05-21T09:21:29.599747Z",
     "iopub.status.busy": "2025-05-21T09:21:29.599247Z",
     "iopub.status.idle": "2025-05-21T09:21:49.545161Z",
     "shell.execute_reply": "2025-05-21T09:21:49.544265Z",
     "shell.execute_reply.started": "2025-05-21T09:21:29.599711Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "env = gym.make(\"CarRacing-v3\", render_mode=\"human\")\n",
    "env = DiscreteCarRacingWrapper(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69032d36",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-21T09:58:25.698933Z",
     "start_time": "2025-05-21T09:58:13.593257Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-21 10:58:19.624902: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from stable_baselines3.common.vec_env import DummyVecEnv, VecFrameStack\n",
    "from stable_baselines3.common.atari_wrappers import WarpFrame\n",
    "\n",
    "env = DummyVecEnv([lambda: DiscreteCarRacingWrapper(gym.make(\"CarRacing-v3\"))])\n",
    "env = VecFrameStack(env, n_stack=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "891184d7-4cd5-49c0-9553-4d9916bfc2de",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-21T09:48:46.627731Z",
     "start_time": "2025-05-21T09:48:46.624978Z"
    },
    "execution": {
     "iopub.status.busy": "2025-05-21T09:25:38.299591Z",
     "iopub.status.idle": "2025-05-21T09:25:38.300166Z",
     "shell.execute_reply": "2025-05-21T09:25:38.299925Z",
     "shell.execute_reply.started": "2025-05-21T09:25:38.299906Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#%pip install \"stable-baselines3[extra]\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f4f160a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-21T09:57:02.181402Z",
     "start_time": "2025-05-21T09:57:02.177878Z"
    }
   },
   "source": [
    "**DQN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec1ba086-576f-4d01-932a-e0a8da6a8c34",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-21T09:54:54.734192Z",
     "start_time": "2025-05-21T09:48:52.419322Z"
    },
    "execution": {
     "iopub.execute_input": "2025-05-21T09:27:30.901409Z",
     "iopub.status.busy": "2025-05-21T09:27:30.901009Z",
     "iopub.status.idle": "2025-05-21T09:27:32.293477Z",
     "shell.execute_reply": "2025-05-21T09:27:32.291986Z",
     "shell.execute_reply.started": "2025-05-21T09:27:30.901380Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-21 10:48:58.376514: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Wrapping the env in a VecTransposeImage.\n",
      "Logging to ./dqn_car_racing_tensorboard/DQN_2\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -24.8    |\n",
      "|    exploration_rate | 0.02     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4        |\n",
      "|    fps              | 33       |\n",
      "|    time_elapsed     | 72       |\n",
      "|    total_timesteps  | 2401     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0241   |\n",
      "|    n_updates        | 350      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 800      |\n",
      "|    ep_rew_mean      | -48.7    |\n",
      "|    exploration_rate | 0.02     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8        |\n",
      "|    fps              | 29       |\n",
      "|    time_elapsed     | 215      |\n",
      "|    total_timesteps  | 6401     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0716   |\n",
      "|    n_updates        | 1350     |\n",
      "----------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.dqn.dqn.DQN at 0x197db5650>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from stable_baselines3 import DQN\n",
    "from stable_baselines3.common.env_checker import check_env\n",
    "\n",
    "\n",
    "check_env(env, warn=True)\n",
    "\n",
    "model = DQN(\n",
    "    policy=\"CnnPolicy\",\n",
    "    env=env,\n",
    "    learning_rate=1e-4,\n",
    "    buffer_size=100_000,\n",
    "    learning_starts=10_000,\n",
    "    batch_size=64,\n",
    "    train_freq=1,\n",
    "    target_update_interval=1000,\n",
    "    exploration_fraction=0.1,\n",
    "    exploration_final_eps=0.01,\n",
    "    tensorboard_log=\"./dqn_car_racing_tensorboard/\",\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "\n",
    "model.learn(total_timesteps=1_000_000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d31d9a9f",
   "metadata": {},
   "source": [
    "**PPO**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "74acd158",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-21T10:15:50.356191Z",
     "start_time": "2025-05-21T10:01:22.931210Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Wrapping the env in a VecTransposeImage.\n",
      "Logging to ./ppo_car_racing_tensorboard/PPO_4\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -55.9    |\n",
      "| time/              |          |\n",
      "|    fps             | 36       |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 28       |\n",
      "|    total_timesteps | 1024     |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | -58.8       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 35          |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 58          |\n",
      "|    total_timesteps      | 2048        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006197861 |\n",
      "|    clip_fraction        | 0.0723      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.25       |\n",
      "|    explained_variance   | 0.0014      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.252       |\n",
      "|    n_updates            | 4           |\n",
      "|    policy_gradient_loss | -0.00621    |\n",
      "|    std                  | 0.998       |\n",
      "|    value_loss           | 0.719       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1e+03      |\n",
      "|    ep_rew_mean          | -60.8      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 33         |\n",
      "|    iterations           | 3          |\n",
      "|    time_elapsed         | 92         |\n",
      "|    total_timesteps      | 3072       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00502342 |\n",
      "|    clip_fraction        | 0.0281     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -4.25      |\n",
      "|    explained_variance   | 0.0833     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 0.166      |\n",
      "|    n_updates            | 8          |\n",
      "|    policy_gradient_loss | -0.00392   |\n",
      "|    std                  | 0.997      |\n",
      "|    value_loss           | 0.668      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1e+03     |\n",
      "|    ep_rew_mean          | -59.3     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 33        |\n",
      "|    iterations           | 4         |\n",
      "|    time_elapsed         | 122       |\n",
      "|    total_timesteps      | 4096      |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0094894 |\n",
      "|    clip_fraction        | 0.114     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -4.25     |\n",
      "|    explained_variance   | 0.132     |\n",
      "|    learning_rate        | 0.00025   |\n",
      "|    loss                 | 0.227     |\n",
      "|    n_updates            | 12        |\n",
      "|    policy_gradient_loss | -0.00614  |\n",
      "|    std                  | 0.995     |\n",
      "|    value_loss           | 0.54      |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | -54.9       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 33          |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 151         |\n",
      "|    total_timesteps      | 5120        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007715971 |\n",
      "|    clip_fraction        | 0.0747      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.24       |\n",
      "|    explained_variance   | 0.369       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.205       |\n",
      "|    n_updates            | 16          |\n",
      "|    policy_gradient_loss | -0.00402    |\n",
      "|    std                  | 0.993       |\n",
      "|    value_loss           | 0.57        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1e+03        |\n",
      "|    ep_rew_mean          | -52.1        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 33           |\n",
      "|    iterations           | 6            |\n",
      "|    time_elapsed         | 181          |\n",
      "|    total_timesteps      | 6144         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0103154965 |\n",
      "|    clip_fraction        | 0.117        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.23        |\n",
      "|    explained_variance   | 0.227        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.242        |\n",
      "|    n_updates            | 20           |\n",
      "|    policy_gradient_loss | -0.00184     |\n",
      "|    std                  | 0.992        |\n",
      "|    value_loss           | 0.742        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1e+03        |\n",
      "|    ep_rew_mean          | -49.7        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 34           |\n",
      "|    iterations           | 7            |\n",
      "|    time_elapsed         | 210          |\n",
      "|    total_timesteps      | 7168         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065864557 |\n",
      "|    clip_fraction        | 0.112        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.23        |\n",
      "|    explained_variance   | 0.335        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.375        |\n",
      "|    n_updates            | 24           |\n",
      "|    policy_gradient_loss | -0.00523     |\n",
      "|    std                  | 0.991        |\n",
      "|    value_loss           | 0.759        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | -51.8       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 34          |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 239         |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008592448 |\n",
      "|    clip_fraction        | 0.0925      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.23       |\n",
      "|    explained_variance   | 0.0908      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.55        |\n",
      "|    n_updates            | 28          |\n",
      "|    policy_gradient_loss | -0.00418    |\n",
      "|    std                  | 0.988       |\n",
      "|    value_loss           | 1.03        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1e+03        |\n",
      "|    ep_rew_mean          | -51.8        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 34           |\n",
      "|    iterations           | 9            |\n",
      "|    time_elapsed         | 269          |\n",
      "|    total_timesteps      | 9216         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016460768 |\n",
      "|    clip_fraction        | 0.0603       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.22        |\n",
      "|    explained_variance   | -0.0702      |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.145        |\n",
      "|    n_updates            | 32           |\n",
      "|    policy_gradient_loss | 0.000219     |\n",
      "|    std                  | 0.987        |\n",
      "|    value_loss           | 0.431        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | -51.1       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 34          |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 298         |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004681877 |\n",
      "|    clip_fraction        | 0.0566      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.22       |\n",
      "|    explained_variance   | 0.167       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.257       |\n",
      "|    n_updates            | 36          |\n",
      "|    policy_gradient_loss | -0.00147    |\n",
      "|    std                  | 0.987       |\n",
      "|    value_loss           | 0.701       |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1e+03        |\n",
      "|    ep_rew_mean          | -49.7        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 34           |\n",
      "|    iterations           | 11           |\n",
      "|    time_elapsed         | 328          |\n",
      "|    total_timesteps      | 11264        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033331197 |\n",
      "|    clip_fraction        | 0.0505       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.22        |\n",
      "|    explained_variance   | 0.406        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.237        |\n",
      "|    n_updates            | 40           |\n",
      "|    policy_gradient_loss | 0.00143      |\n",
      "|    std                  | 0.986        |\n",
      "|    value_loss           | 0.736        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | -47.5       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 34          |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 357         |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005869005 |\n",
      "|    clip_fraction        | 0.0645      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.21       |\n",
      "|    explained_variance   | 0.225       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.257       |\n",
      "|    n_updates            | 44          |\n",
      "|    policy_gradient_loss | -0.00296    |\n",
      "|    std                  | 0.982       |\n",
      "|    value_loss           | 0.546       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | -46         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 34          |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 386         |\n",
      "|    total_timesteps      | 13312       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012834993 |\n",
      "|    clip_fraction        | 0.156       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.2        |\n",
      "|    explained_variance   | 0.101       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.243       |\n",
      "|    n_updates            | 48          |\n",
      "|    policy_gradient_loss | -0.00405    |\n",
      "|    std                  | 0.982       |\n",
      "|    value_loss           | 0.821       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1e+03        |\n",
      "|    ep_rew_mean          | -46.2        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 34           |\n",
      "|    iterations           | 14           |\n",
      "|    time_elapsed         | 416          |\n",
      "|    total_timesteps      | 14336        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0070470264 |\n",
      "|    clip_fraction        | 0.0449       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.2         |\n",
      "|    explained_variance   | 0.1          |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.248        |\n",
      "|    n_updates            | 52           |\n",
      "|    policy_gradient_loss | -0.00123     |\n",
      "|    std                  | 0.982        |\n",
      "|    value_loss           | 0.826        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | -45.6       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 34          |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 446         |\n",
      "|    total_timesteps      | 15360       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018970761 |\n",
      "|    clip_fraction        | 0.145       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.2        |\n",
      "|    explained_variance   | 0.588       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.305       |\n",
      "|    n_updates            | 56          |\n",
      "|    policy_gradient_loss | -0.0049     |\n",
      "|    std                  | 0.981       |\n",
      "|    value_loss           | 0.644       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1e+03        |\n",
      "|    ep_rew_mean          | -43.3        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 34           |\n",
      "|    iterations           | 16           |\n",
      "|    time_elapsed         | 475          |\n",
      "|    total_timesteps      | 16384        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0066693136 |\n",
      "|    clip_fraction        | 0.0691       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.2         |\n",
      "|    explained_variance   | 0.635        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.0913       |\n",
      "|    n_updates            | 60           |\n",
      "|    policy_gradient_loss | -0.00322     |\n",
      "|    std                  | 0.979        |\n",
      "|    value_loss           | 0.662        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | -41.8       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 34          |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 504         |\n",
      "|    total_timesteps      | 17408       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010845863 |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.19       |\n",
      "|    explained_variance   | 0.6         |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.269       |\n",
      "|    n_updates            | 64          |\n",
      "|    policy_gradient_loss | -0.00486    |\n",
      "|    std                  | 0.978       |\n",
      "|    value_loss           | 0.937       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1e+03        |\n",
      "|    ep_rew_mean          | -39.5        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 34           |\n",
      "|    iterations           | 18           |\n",
      "|    time_elapsed         | 537          |\n",
      "|    total_timesteps      | 18432        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0070976703 |\n",
      "|    clip_fraction        | 0.0815       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.19        |\n",
      "|    explained_variance   | 0.821        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.222        |\n",
      "|    n_updates            | 68           |\n",
      "|    policy_gradient_loss | -0.0041      |\n",
      "|    std                  | 0.976        |\n",
      "|    value_loss           | 0.719        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | -39.9       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 34          |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 565         |\n",
      "|    total_timesteps      | 19456       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008995606 |\n",
      "|    clip_fraction        | 0.136       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.18       |\n",
      "|    explained_variance   | 0.871       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.257       |\n",
      "|    n_updates            | 72          |\n",
      "|    policy_gradient_loss | -0.00909    |\n",
      "|    std                  | 0.974       |\n",
      "|    value_loss           | 0.818       |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1e+03        |\n",
      "|    ep_rew_mean          | -41.4        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 34           |\n",
      "|    iterations           | 20           |\n",
      "|    time_elapsed         | 594          |\n",
      "|    total_timesteps      | 20480        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0053090258 |\n",
      "|    clip_fraction        | 0.151        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.17        |\n",
      "|    explained_variance   | 0.847        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.0479       |\n",
      "|    n_updates            | 76           |\n",
      "|    policy_gradient_loss | -0.00549     |\n",
      "|    std                  | 0.97         |\n",
      "|    value_loss           | 0.304        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | -41.7       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 34          |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 622         |\n",
      "|    total_timesteps      | 21504       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013420424 |\n",
      "|    clip_fraction        | 0.113       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.16       |\n",
      "|    explained_variance   | 0.909       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.0915      |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.000757   |\n",
      "|    std                  | 0.968       |\n",
      "|    value_loss           | 0.421       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | -43.3       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 34          |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 652         |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008605289 |\n",
      "|    clip_fraction        | 0.0955      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.16       |\n",
      "|    explained_variance   | 0.914       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.0285      |\n",
      "|    n_updates            | 84          |\n",
      "|    policy_gradient_loss | -0.000831   |\n",
      "|    std                  | 0.967       |\n",
      "|    value_loss           | 0.255       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1e+03        |\n",
      "|    ep_rew_mean          | -44.3        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 34           |\n",
      "|    iterations           | 23           |\n",
      "|    time_elapsed         | 682          |\n",
      "|    total_timesteps      | 23552        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0054730284 |\n",
      "|    clip_fraction        | 0.11         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.15        |\n",
      "|    explained_variance   | 0.947        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.0459       |\n",
      "|    n_updates            | 88           |\n",
      "|    policy_gradient_loss | -0.00307     |\n",
      "|    std                  | 0.966        |\n",
      "|    value_loss           | 0.222        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1e+03        |\n",
      "|    ep_rew_mean          | -45.4        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 34           |\n",
      "|    iterations           | 24           |\n",
      "|    time_elapsed         | 712          |\n",
      "|    total_timesteps      | 24576        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0052870964 |\n",
      "|    clip_fraction        | 0.101        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.15        |\n",
      "|    explained_variance   | 0.933        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.045        |\n",
      "|    n_updates            | 92           |\n",
      "|    policy_gradient_loss | -0.00181     |\n",
      "|    std                  | 0.966        |\n",
      "|    value_loss           | 0.312        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | -44         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 34          |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 741         |\n",
      "|    total_timesteps      | 25600       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014875004 |\n",
      "|    clip_fraction        | 0.162       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.15       |\n",
      "|    explained_variance   | 0.895       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.114       |\n",
      "|    n_updates            | 96          |\n",
      "|    policy_gradient_loss | -0.00525    |\n",
      "|    std                  | 0.966       |\n",
      "|    value_loss           | 0.623       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | -43.9       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 34          |\n",
      "|    iterations           | 26          |\n",
      "|    time_elapsed         | 771         |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009139113 |\n",
      "|    clip_fraction        | 0.094       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.15       |\n",
      "|    explained_variance   | 0.858       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.053       |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.00103    |\n",
      "|    std                  | 0.965       |\n",
      "|    value_loss           | 0.564       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | -44.4       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 34          |\n",
      "|    iterations           | 27          |\n",
      "|    time_elapsed         | 800         |\n",
      "|    total_timesteps      | 27648       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008350944 |\n",
      "|    clip_fraction        | 0.082       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.15       |\n",
      "|    explained_variance   | 0.937       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.163       |\n",
      "|    n_updates            | 104         |\n",
      "|    policy_gradient_loss | -0.00163    |\n",
      "|    std                  | 0.963       |\n",
      "|    value_loss           | 0.273       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1e+03        |\n",
      "|    ep_rew_mean          | -43.9        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 34           |\n",
      "|    iterations           | 28           |\n",
      "|    time_elapsed         | 829          |\n",
      "|    total_timesteps      | 28672        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0070518013 |\n",
      "|    clip_fraction        | 0.093        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.14        |\n",
      "|    explained_variance   | 0.948        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.261        |\n",
      "|    n_updates            | 108          |\n",
      "|    policy_gradient_loss | -0.00346     |\n",
      "|    std                  | 0.961        |\n",
      "|    value_loss           | 0.621        |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | -43.8       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 34          |\n",
      "|    iterations           | 29          |\n",
      "|    time_elapsed         | 859         |\n",
      "|    total_timesteps      | 29696       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010922686 |\n",
      "|    clip_fraction        | 0.0845      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.14       |\n",
      "|    explained_variance   | 0.966       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.159       |\n",
      "|    n_updates            | 112         |\n",
      "|    policy_gradient_loss | -0.00645    |\n",
      "|    std                  | 0.959       |\n",
      "|    value_loss           | 0.403       |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 18\u001b[0m\n\u001b[1;32m      4\u001b[0m env \u001b[38;5;241m=\u001b[39m gym\u001b[38;5;241m.\u001b[39mmake(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCarRacing-v3\u001b[39m\u001b[38;5;124m\"\u001b[39m, render_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhuman\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      6\u001b[0m model \u001b[38;5;241m=\u001b[39m PPO(\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCnnPolicy\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      8\u001b[0m     env\u001b[38;5;241m=\u001b[39menv,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     15\u001b[0m     clip_range\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m,\n\u001b[1;32m     16\u001b[0m )\n\u001b[0;32m---> 18\u001b[0m model\u001b[38;5;241m.\u001b[39mlearn(total_timesteps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100_000\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/stable_baselines3/ppo/ppo.py:311\u001b[0m, in \u001b[0;36mPPO.learn\u001b[0;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[1;32m    302\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlearn\u001b[39m(\n\u001b[1;32m    303\u001b[0m     \u001b[38;5;28mself\u001b[39m: SelfPPO,\n\u001b[1;32m    304\u001b[0m     total_timesteps: \u001b[38;5;28mint\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    309\u001b[0m     progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    310\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m SelfPPO:\n\u001b[0;32m--> 311\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mlearn(\n\u001b[1;32m    312\u001b[0m         total_timesteps\u001b[38;5;241m=\u001b[39mtotal_timesteps,\n\u001b[1;32m    313\u001b[0m         callback\u001b[38;5;241m=\u001b[39mcallback,\n\u001b[1;32m    314\u001b[0m         log_interval\u001b[38;5;241m=\u001b[39mlog_interval,\n\u001b[1;32m    315\u001b[0m         tb_log_name\u001b[38;5;241m=\u001b[39mtb_log_name,\n\u001b[1;32m    316\u001b[0m         reset_num_timesteps\u001b[38;5;241m=\u001b[39mreset_num_timesteps,\n\u001b[1;32m    317\u001b[0m         progress_bar\u001b[38;5;241m=\u001b[39mprogress_bar,\n\u001b[1;32m    318\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/stable_baselines3/common/on_policy_algorithm.py:323\u001b[0m, in \u001b[0;36mOnPolicyAlgorithm.learn\u001b[0;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[1;32m    320\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    322\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_timesteps \u001b[38;5;241m<\u001b[39m total_timesteps:\n\u001b[0;32m--> 323\u001b[0m     continue_training \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcollect_rollouts(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv, callback, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrollout_buffer, n_rollout_steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_steps)\n\u001b[1;32m    325\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m continue_training:\n\u001b[1;32m    326\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/stable_baselines3/common/on_policy_algorithm.py:218\u001b[0m, in \u001b[0;36mOnPolicyAlgorithm.collect_rollouts\u001b[0;34m(self, env, callback, rollout_buffer, n_rollout_steps)\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    214\u001b[0m         \u001b[38;5;66;03m# Otherwise, clip the actions to avoid out of bound error\u001b[39;00m\n\u001b[1;32m    215\u001b[0m         \u001b[38;5;66;03m# as we are sampling from an unbounded Gaussian distribution\u001b[39;00m\n\u001b[1;32m    216\u001b[0m         clipped_actions \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mclip(actions, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_space\u001b[38;5;241m.\u001b[39mlow, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_space\u001b[38;5;241m.\u001b[39mhigh)\n\u001b[0;32m--> 218\u001b[0m new_obs, rewards, dones, infos \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mstep(clipped_actions)\n\u001b[1;32m    220\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_timesteps \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mnum_envs\n\u001b[1;32m    222\u001b[0m \u001b[38;5;66;03m# Give access to local variables\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/stable_baselines3/common/vec_env/base_vec_env.py:206\u001b[0m, in \u001b[0;36mVecEnv.step\u001b[0;34m(self, actions)\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    200\u001b[0m \u001b[38;5;124;03mStep the environments with the given action\u001b[39;00m\n\u001b[1;32m    201\u001b[0m \n\u001b[1;32m    202\u001b[0m \u001b[38;5;124;03m:param actions: the action\u001b[39;00m\n\u001b[1;32m    203\u001b[0m \u001b[38;5;124;03m:return: observation, reward, done, information\u001b[39;00m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_async(actions)\n\u001b[0;32m--> 206\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_wait()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/stable_baselines3/common/vec_env/vec_transpose.py:97\u001b[0m, in \u001b[0;36mVecTransposeImage.step_wait\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep_wait\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m VecEnvStepReturn:\n\u001b[0;32m---> 97\u001b[0m     observations, rewards, dones, infos \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvenv\u001b[38;5;241m.\u001b[39mstep_wait()\n\u001b[1;32m     99\u001b[0m     \u001b[38;5;66;03m# Transpose the terminal observations\u001b[39;00m\n\u001b[1;32m    100\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m idx, done \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(dones):\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/stable_baselines3/common/vec_env/dummy_vec_env.py:58\u001b[0m, in \u001b[0;36mDummyVecEnv.step_wait\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep_wait\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m VecEnvStepReturn:\n\u001b[1;32m     56\u001b[0m     \u001b[38;5;66;03m# Avoid circular imports\u001b[39;00m\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m env_idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_envs):\n\u001b[0;32m---> 58\u001b[0m         obs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuf_rews[env_idx], terminated, truncated, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuf_infos[env_idx] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menvs[env_idx]\u001b[38;5;241m.\u001b[39mstep(\n\u001b[1;32m     59\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactions[env_idx]\n\u001b[1;32m     60\u001b[0m         )\n\u001b[1;32m     61\u001b[0m         \u001b[38;5;66;03m# convert to SB3 VecEnv api\u001b[39;00m\n\u001b[1;32m     62\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuf_dones[env_idx] \u001b[38;5;241m=\u001b[39m terminated \u001b[38;5;129;01mor\u001b[39;00m truncated\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/stable_baselines3/common/monitor.py:94\u001b[0m, in \u001b[0;36mMonitor.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mneeds_reset:\n\u001b[1;32m     93\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTried to step environment that needs reset\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 94\u001b[0m observation, reward, terminated, truncated, info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv\u001b[38;5;241m.\u001b[39mstep(action)\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrewards\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mfloat\u001b[39m(reward))\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m terminated \u001b[38;5;129;01mor\u001b[39;00m truncated:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/gymnasium/wrappers/common.py:125\u001b[0m, in \u001b[0;36mTimeLimit.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep\u001b[39m(\n\u001b[1;32m    113\u001b[0m     \u001b[38;5;28mself\u001b[39m, action: ActType\n\u001b[1;32m    114\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mtuple\u001b[39m[ObsType, SupportsFloat, \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any]]:\n\u001b[1;32m    115\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Steps through the environment and if the number of steps elapsed exceeds ``max_episode_steps`` then truncate.\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \n\u001b[1;32m    117\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    123\u001b[0m \n\u001b[1;32m    124\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 125\u001b[0m     observation, reward, terminated, truncated, info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv\u001b[38;5;241m.\u001b[39mstep(action)\n\u001b[1;32m    126\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_elapsed_steps \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    128\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_elapsed_steps \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_max_episode_steps:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/gymnasium/wrappers/common.py:393\u001b[0m, in \u001b[0;36mOrderEnforcing.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    391\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_reset:\n\u001b[1;32m    392\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ResetNeeded(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot call env.step() before calling env.reset()\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 393\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mstep(action)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/gymnasium/core.py:322\u001b[0m, in \u001b[0;36mWrapper.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep\u001b[39m(\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;28mself\u001b[39m, action: WrapperActType\n\u001b[1;32m    320\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mtuple\u001b[39m[WrapperObsType, SupportsFloat, \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any]]:\n\u001b[1;32m    321\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Uses the :meth:`step` of the :attr:`env` that can be overwritten to change the returned data.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 322\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv\u001b[38;5;241m.\u001b[39mstep(action)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/gymnasium/wrappers/common.py:285\u001b[0m, in \u001b[0;36mPassiveEnvChecker.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    283\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m env_step_passive_checker(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv, action)\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 285\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv\u001b[38;5;241m.\u001b[39mstep(action)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/gymnasium/envs/box2d/car_racing.py:563\u001b[0m, in \u001b[0;36mCarRacing.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    560\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mworld\u001b[38;5;241m.\u001b[39mStep(\u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m/\u001b[39m FPS, \u001b[38;5;241m6\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m30\u001b[39m, \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m30\u001b[39m)\n\u001b[1;32m    561\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mt \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m/\u001b[39m FPS\n\u001b[0;32m--> 563\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_render(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstate_pixels\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    565\u001b[0m step_reward \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    566\u001b[0m terminated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/gymnasium/envs/box2d/car_racing.py:628\u001b[0m, in \u001b[0;36mCarRacing._render\u001b[0;34m(self, mode)\u001b[0m\n\u001b[1;32m    625\u001b[0m trans \u001b[38;5;241m=\u001b[39m pygame\u001b[38;5;241m.\u001b[39mmath\u001b[38;5;241m.\u001b[39mVector2((scroll_x, scroll_y))\u001b[38;5;241m.\u001b[39mrotate_rad(angle)\n\u001b[1;32m    626\u001b[0m trans \u001b[38;5;241m=\u001b[39m (WINDOW_W \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m+\u001b[39m trans[\u001b[38;5;241m0\u001b[39m], WINDOW_H \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m4\u001b[39m \u001b[38;5;241m+\u001b[39m trans[\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m--> 628\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_render_road(zoom, trans, angle)\n\u001b[1;32m    629\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcar\u001b[38;5;241m.\u001b[39mdraw(\n\u001b[1;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msurf,\n\u001b[1;32m    631\u001b[0m     zoom,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    634\u001b[0m     mode \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstate_pixels_list\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstate_pixels\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m    635\u001b[0m )\n\u001b[1;32m    637\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msurf \u001b[38;5;241m=\u001b[39m pygame\u001b[38;5;241m.\u001b[39mtransform\u001b[38;5;241m.\u001b[39mflip(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msurf, \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/gymnasium/envs/box2d/car_racing.py:698\u001b[0m, in \u001b[0;36mCarRacing._render_road\u001b[0;34m(self, zoom, translation, angle)\u001b[0m\n\u001b[1;32m    696\u001b[0m poly \u001b[38;5;241m=\u001b[39m [(p[\u001b[38;5;241m0\u001b[39m], p[\u001b[38;5;241m1\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m poly]\n\u001b[1;32m    697\u001b[0m color \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mint\u001b[39m(c) \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m color]\n\u001b[0;32m--> 698\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_draw_colored_polygon(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msurf, poly, color, zoom, translation, angle)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/gymnasium/envs/box2d/car_racing.py:786\u001b[0m, in \u001b[0;36mCarRacing._draw_colored_polygon\u001b[0;34m(self, surface, poly, color, zoom, translation, angle, clip)\u001b[0m\n\u001b[1;32m    780\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m clip \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28many\u001b[39m(\n\u001b[1;32m    781\u001b[0m     (\u001b[38;5;241m-\u001b[39mMAX_SHAPE_DIM \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m coord[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m WINDOW_W \u001b[38;5;241m+\u001b[39m MAX_SHAPE_DIM)\n\u001b[1;32m    782\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;241m-\u001b[39mMAX_SHAPE_DIM \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m coord[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m WINDOW_H \u001b[38;5;241m+\u001b[39m MAX_SHAPE_DIM)\n\u001b[1;32m    783\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m coord \u001b[38;5;129;01min\u001b[39;00m poly\n\u001b[1;32m    784\u001b[0m ):\n\u001b[1;32m    785\u001b[0m     gfxdraw\u001b[38;5;241m.\u001b[39maapolygon(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msurf, poly, color)\n\u001b[0;32m--> 786\u001b[0m     gfxdraw\u001b[38;5;241m.\u001b[39mfilled_polygon(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msurf, poly, color)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "from stable_baselines3 import PPO\n",
    "\n",
    "env = gym.make(\"CarRacing-v3\", render_mode=\"human\")\n",
    "\n",
    "model = PPO(\n",
    "    \"CnnPolicy\",\n",
    "    env=env,\n",
    "    verbose=1,\n",
    "    tensorboard_log=\"./ppo_car_racing_tensorboard/\",\n",
    "    learning_rate=2.5e-4,\n",
    "    n_steps=1024,\n",
    "    batch_size=64,\n",
    "    n_epochs=4,\n",
    "    clip_range=0.2,\n",
    ")\n",
    "\n",
    "model.learn(total_timesteps=100_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c2f6fbd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f12b7fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e5c92e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbdeeadb-f5a5-4541-a72f-b8fff75cddf1",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-05-21T09:47:10.163Z"
    },
    "execution": {
     "iopub.execute_input": "2025-05-21T09:22:44.170381Z",
     "iopub.status.busy": "2025-05-21T09:22:44.169938Z",
     "iopub.status.idle": "2025-05-21T09:22:44.177444Z",
     "shell.execute_reply": "2025-05-21T09:22:44.176616Z",
     "shell.execute_reply.started": "2025-05-21T09:22:44.170348Z"
    }
   },
   "outputs": [],
   "source": [
    "obs, _ = env.reset()\n",
    "done = False\n",
    "while not done:\n",
    "    action, _ = model.predict(obs)\n",
    "    obs, reward, done, truncated, info = env.step(action)\n",
    "    env.render()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b7ffcdb-ba2e-4fa3-b8a9-33d526e7c6eb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-21T09:26:24.586146Z",
     "iopub.status.busy": "2025-05-21T09:26:24.585719Z",
     "iopub.status.idle": "2025-05-21T09:26:35.010754Z",
     "shell.execute_reply": "2025-05-21T09:26:35.009344Z",
     "shell.execute_reply.started": "2025-05-21T09:26:24.586115Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a81e4b2b-ea3e-4026-be88-3b246477e126",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
